{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pre_proc_functions as proc\n",
    "import os\n",
    "import train_functions as tr\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as albu\n",
    "from sklearn.metrics import jaccard_score, f1_score\n",
    "from segmentation_models_pytorch.losses import JaccardLoss\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Raw Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"/home/zimu/Desktop/Code/Skull_Stripe_dataset/zhao_data/mask\"\n",
    "msk_dir = \"/home/zimu/Desktop/Code/Skull_Stripe_dataset/zhao_data/mask\"\n",
    "images_output_dir = \"./split\"\n",
    "img_fixed = \"_mc_restore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use if images needs swapdim\n",
    "#proc.apply_fslswapdim_to_folder(img_dir, img_dir + '_sw')\n",
    "#proc.apply_fslswapdim_to_folder(msk_dir, msk_dir + '_sw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc.proc_img_masks('data/img','data/mask',out_dir='data_split',img_fixed = \"_mc_restore\",test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train_dir_sag = 'data_split/sag/train_img'\n",
    "y_train_dir_sag = 'data_split/sag/train_masks'\n",
    "\n",
    "x_valid_dir_sag = 'data_split/sag/valid_img'\n",
    "y_valid_dir_sag = 'data_split/sag/valid_masks'\n",
    "\n",
    "x_train_dir_cor = 'data_split/cor/train_img'\n",
    "y_train_dir_cor = 'zhao_data_split/cor/train_masks'\n",
    "\n",
    "x_valid_dir_cor = 'data_split/cor/valid_img'\n",
    "y_valid_dir_cor = 'data_split/cor/valid_masks'\n",
    "\n",
    "x_train_dir_ax = 'data_split/ax/train_img'\n",
    "y_train_dir_ax = 'data_split/ax/train_masks'\n",
    "\n",
    "x_valid_dir_ax = 'data_split/ax/valid_img'\n",
    "y_valid_dir_ax = 'data_split/ax/valid_masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "views = ['sag', 'cor', 'ax']\n",
    "CLASSES = ['brain']\n",
    "DEVICE = 'cuda'\n",
    "models = {'Unet':{'sag':{},'cor':{},'ax':{}}}\n",
    "preprocessing_fn = {}\n",
    "lr = 0.0001\n",
    "\n",
    "for i, view in enumerate(views):\n",
    "    # create segmentation model with pretrained encoder\n",
    "    # Make sure the model state and path are pointed to the correct encoders\n",
    "    model = torch.load(f'./model_checkpoints/Unet_efficientnet-b3_{view}.pth')\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)  # Whatever optimizer you used, e.g., Adam\n",
    "    checkpoint = torch.load(f'./model_checkpoints/Unet_efficientnet-b3_{view}_state.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    preprocessing_fn_i = smp.encoders.get_preprocessing_fn('efficientnet-b3', 'imagenet')\n",
    "    models['Unet'][view]['model'] = model\n",
    "    models['Unet'][view]['optimizer'] = optimizer\n",
    "    models['Unet'][view]['start_epoch'] = 0\n",
    "    models['Unet'][view]['loss'] = loss\n",
    "    preprocessing_fn[view] = preprocessing_fn_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loaders = {}\n",
    "valid_loaders = {}\n",
    "\n",
    "batchsize = 16\n",
    "\n",
    "train_dataset_sag = tr.Dataset(\n",
    "    x_train_dir_sag, \n",
    "    y_train_dir_sag, \n",
    "    augmentation=None,#get_training_augmentation(), \n",
    "    preprocessing=tr.get_preprocessing(preprocessing_fn['sag']),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "valid_dataset_sag = tr.Dataset(\n",
    "    x_valid_dir_sag, \n",
    "    y_valid_dir_sag, \n",
    "    augmentation=None, \n",
    "    preprocessing=tr.get_preprocessing(preprocessing_fn['sag']),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "train_loader_sag = DataLoader(train_dataset_sag, batch_size=batchsize, shuffle=True, num_workers=12)\n",
    "valid_loader_sag = DataLoader(valid_dataset_sag, batch_size=batchsize, shuffle=False, num_workers=12)\n",
    "\n",
    "train_loaders['sag'] = train_loader_sag\n",
    "valid_loaders['sag'] = valid_loader_sag\n",
    "\n",
    "train_dataset_cor = tr.Dataset(\n",
    "    x_train_dir_cor, \n",
    "    y_train_dir_cor, \n",
    "    augmentation=None,#get_training_augmentation(), \n",
    "    preprocessing=tr.get_preprocessing(preprocessing_fn['cor']),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "valid_dataset_cor = tr.Dataset(\n",
    "    x_valid_dir_cor, \n",
    "    y_valid_dir_cor, \n",
    "    augmentation=None, \n",
    "    preprocessing=tr.get_preprocessing(preprocessing_fn['cor']),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "train_loader_cor = DataLoader(train_dataset_cor, batch_size=batchsize, shuffle=True, num_workers=12)\n",
    "valid_loader_cor = DataLoader(valid_dataset_cor, batch_size=batchsize, shuffle=False, num_workers=12)\n",
    "\n",
    "train_loaders['cor'] = train_loader_cor\n",
    "valid_loaders['cor'] = valid_loader_cor\n",
    "\n",
    "train_dataset_ax = tr.Dataset(\n",
    "    x_train_dir_ax, \n",
    "    y_train_dir_ax, \n",
    "    augmentation=None,#get_training_augmentation(), \n",
    "    preprocessing=tr.get_preprocessing(preprocessing_fn['ax']),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "valid_dataset_ax = tr.Dataset(\n",
    "    x_valid_dir_ax, \n",
    "    y_valid_dir_ax, \n",
    "    augmentation=None, \n",
    "    preprocessing=tr.get_preprocessing(preprocessing_fn['ax']),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "train_loader_ax = DataLoader(train_dataset_ax, batch_size=batchsize, shuffle=True, num_workers=12)\n",
    "valid_loader_ax = DataLoader(valid_dataset_ax, batch_size=batchsize, shuffle=False, num_workers=12)\n",
    "\n",
    "train_loaders['ax'] = train_loader_ax\n",
    "valid_loaders['ax'] = valid_loader_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the initial model here\n",
    "sample_ex = next(iter(train_loaders[views[0]]))\n",
    "tr.test_model(models['Unet'][views[0]]['model'], 1, sample_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, view in enumerate(views):\n",
    "            if view != 'sag':\n",
    "                    sample_ex = next(iter(train_loaders[view]))\n",
    "\n",
    "\n",
    "            train_loss_list, val_loss_list = [], []\n",
    "            train_iou_list, val_iou_list = [], []\n",
    "            train_dice_list, val_dice_list = [], []\n",
    "            model = models['Unet'][view]['model']\n",
    "            print(f'training {view} __________________ 2024')\n",
    "            #print(model)\n",
    "            EPOCHS = 30\n",
    "            device = 'cuda'\n",
    "\n",
    "            criterion = JaccardLoss('binary')\n",
    "            optimizer = models['Unet'][view]['optimizer']\n",
    "            model.to(device)\n",
    "\n",
    "            for epoch in tqdm(range(0, EPOCHS), desc=\"epoch\", leave=False, colour='green'):\n",
    "                model.train()\n",
    "                train_loss, train_iou, train_dice, train_hd = 0, 0, 0, 0\n",
    "                for i, data in enumerate(tqdm(train_loaders[view], desc=\"training\", leave=False, colour='red')):\n",
    "                    img, mask = data\n",
    "                    img, mask = img.to(device), mask.to(device)\n",
    "\n",
    "                    # Run prediction\n",
    "                    optimizer.zero_grad()\n",
    "                    y_pred = model(img)\n",
    "                    loss = criterion(y_pred, mask)\n",
    "                    train_loss += loss.item()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # Convert predictions and ground truth to binary (assuming single channel output)\n",
    "                    y_pred_bin = (y_pred.squeeze(1) > 0.5).cpu().numpy().astype(np.uint8)\n",
    "                    mask_bin = mask.cpu().numpy().astype(np.uint8)\n",
    "\n",
    "                    # Update training metrics\n",
    "                    train_iou += jaccard_score(mask_bin.flatten(), y_pred_bin.flatten())\n",
    "                    train_dice += f1_score(mask_bin.flatten(), y_pred_bin.flatten())\n",
    "                    \n",
    "\n",
    "                # Average the training metrics\n",
    "                train_loss /= len(train_loaders[view])\n",
    "                train_iou /= len(train_loaders[view])\n",
    "                train_dice /= len(train_loaders[view])\n",
    "            \n",
    "\n",
    "                # Append training metrics\n",
    "                train_loss_list.append(train_loss)\n",
    "                train_iou_list.append(train_iou)\n",
    "                train_dice_list.append(train_dice)\n",
    "\n",
    "\n",
    "                # Validation\n",
    "                model.eval()\n",
    "                val_loss, val_iou, val_dice, val_hd = 0, 0, 0, 0\n",
    "                for i, data in enumerate(tqdm(valid_loaders[view], desc=\"validation\", leave=False, colour='blue')):\n",
    "                    img, mask = data\n",
    "                    img, mask = img.to(device), mask.to(device)\n",
    "                    with torch.no_grad():\n",
    "                        y_pred = model(img)\n",
    "                        loss = criterion(y_pred, mask)\n",
    "                        val_loss += loss.item()\n",
    "\n",
    "                        # Convert predictions and ground truth to binary (assuming single channel output)\n",
    "                        y_pred_bin = (y_pred.squeeze(1) > 0.5).cpu().numpy().astype(np.uint8)\n",
    "                        mask_bin = mask.cpu().numpy().astype(np.uint8)\n",
    "\n",
    "                        # Update validation metrics\n",
    "                        val_iou += jaccard_score(mask_bin.flatten(), y_pred_bin.flatten())\n",
    "                        val_dice += f1_score(mask_bin.flatten(), y_pred_bin.flatten())\n",
    "                    \n",
    "\n",
    "                # Average the validation metrics\n",
    "                val_loss /= len(valid_loaders[view])\n",
    "                val_iou /= len(valid_loaders[view])\n",
    "                val_dice /= len(valid_loaders[view])\n",
    "\n",
    "\n",
    "                # Append validation metrics\n",
    "                val_loss_list.append(val_loss)\n",
    "                val_iou_list.append(val_iou)\n",
    "                val_dice_list.append(val_dice)\n",
    "\n",
    "\n",
    "                tr.test_model(model, epoch, sample_ex)\n",
    "                print(f'{epoch}_{view}, metrics at: \\ntrain loss - {train_loss} \\ntrain IOU - {train_iou} \\ntrain dice - {train_dice} \\nval loss - {val_loss} \\nval IOU - {val_iou} \\nval_dice - {val_dice}')\n",
    "                torch.save(model, f'./checkpoints/{epoch}_{view}.pth')\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': train_loss,\n",
    "                    # any other metrics you might find useful\n",
    "                }, f'./checkpoints/{epoch}_{view}_state.pth')\n",
    "            # Create a DataFrame and save to CSV\n",
    "            metrics_df = pd.DataFrame({\n",
    "                'Epoch': list(range(1, EPOCHS + 1)),\n",
    "                'Train_Loss': train_loss_list,\n",
    "                'Validation_Loss': val_loss_list,\n",
    "                'Train_IOU': train_iou_list,\n",
    "                'Validation_IOU': val_iou_list,\n",
    "                'Train_Dice': train_dice_list,\n",
    "                'Validation_Dice': val_dice_list,\n",
    "\n",
    "            })\n",
    "            metrics_df.to_csv(f'./checkpoints/{epoch}_{view}_training_metrics.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
